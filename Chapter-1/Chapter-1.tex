%------------------------------%
\chapter{Introduction}
\label{chap:intro}
%------------------------------%

Privacy encompasses both technical and technical aspects. But the
literature in privacy research has focused on these aspects as two
different goals.  One aims to design secured systems with the help of
cryptographic protection. The other aims to protect personal information
by facilitating informed choice options to an individual and assume that
policies and regulations are enforceable. This research tackles
the science of privacy from a sociotechnical viewpoint that bridges the 
two goals.

Human interactions in a society are not merely driven by personal needs
and expectations (defined later in Chapter~\ref{sec:arnor-framework}). 
Others around us and their expectations play a
prominent part on the way we act and interact. A personal agent acts and
interacts on behalf of its human user. 

A \emph{socially intelligent personal agent} (SIPA) adheres to
\emph{social expectations} of multiple \emph{stakeholders}---both
\emph{primary} and \emph{secondary} (defined later in
Chapter~\ref{chap:arnor}), adapts according to the circumstances or
\emph{social context} \citep{Dey-2001-Context}, acts on behalf of its
human user (primary stakeholder), and provides a pleasing social
experience to all of its stakeholders as opposed to an individual
experience to its human user.

%This dissertation addresses the research question of how can we
%engineer social intelligence in personal agents to deliver a
%privacy-preserving social experience. 

The key objectives of this research are: (1) to engineer personal agents
such that they deliver a pleasant social experience relative to the
society, and yet preserve their stakeholders' privacy, and (2) to make
engineering of such personal agents efficient and effective for
developers. We recognize social norms and social context as important
factors that influence the working of such personal agents.

%A distinguishing feature of envisoned agents is that these agents 

%To achieve these objectives, in my research I apply techniques from
%conceptual modeling, argumentation, and crowdsourcing. I have emphasized
%rigorous evaluation of the proposed technique by empirical research, and
%have conducted several studies including human subject studies and
%simulation experiments.

\section{Preliminaries}

In this section we provide a background on privacy, and social norms in
multiagent systems.

\subsection{Privacy}
The concept of privacy encircles several areas. An individual's notion of
privacy is partly based upon the society's notion of privacy and partly
based upon his or her personal experiences \citep{westin1967privacy,
westin2003social}. The general attitude toward sharing personal
information varies from one individual to other.
\citet{westin1967privacy} classifies individuals based on their privacy
preferences: \textit{privacy fundamentalists} are the individuals who
are extremely concerned about their privacy and are reluctant to share
personal information; \textit{privacy pragmatists} are concerned about
privacy but less than fundamentalists and they are willing to disclose
personal information when some benefit is expected; and,
\textit{privacy unconcerned} do not consider privacy loss when
disclosing personal information \citep{westin1967privacy}. The
pragmatists are further grouped into \emph{identity-aware} and \emph{profile-aware}
individuals \citep{spiekermann2009enggprivacy}. Identity-aware
individuals are the ones who are more concerned about revealing
identifying information such as e-mail or physical address rather than
revealing their interests. Profile-aware individuals worry more about
sharing their hobbies, age, interests, or preferences.

Privacy has always been a topic of debate and has no globally
agreed-upon definition \citep{smith2007privacy}. Theorists from the
areas of law, philosophy, sociology, and computer science have all tried
to define privacy in their own perspective.
%
%\cite{schoeman1984philosophical}
%categorizes these definitions into three main categories.
%\begin{enumerate} 
%\item The right an individual has in being able to
%control access to personal information about themselves. 
%\item The
%measure of control an individual has over information about themselves,
%or who has sensory access to them. 
%\item The state of limited access to
%an individual and their personal information. 
%\end{enumerate}
%
The importance of privacy and what it brings to an individual is also
debated. Although there is no single definition, researchers 
acknowledge the idea of privacy, and view it as a
collection of concepts instead of one specific concept
\citep{smith2007privacy}. In this research, we adopt the nuanced notions
(specifically intrusion, appropriation, and disclosure) of privacy as
defined in Solove's taxonomy \citep{solove-2006-taxonomy}.

\subsection{Social Norms and Multiagent Systems}

The concept ``norm'' is used in different disciplines and thus has
variant notions such as social expectations, legal laws, and linguistic
imperatives \citep{Boella2009NormativeSystems}. We adopt the concept of
social norms, which describe interactions between principals in terms of
what they ought to be, or reactions to behaviors, including attempts to
apply sanctions. Thus, social norms regulate the interactions of the
principals involved. Norms and normative systems are gaining increasing
interest in the computer science community. \citet{Meyer+Wieringa-93}
define normative systems as ``systems in the behavior of which norms
play a role and which need normative concepts in order to be described
or specified.'' Normative multiagent systems as a research area can be
defined as the intersection of normative systems and multiagent systems.
Norms govern much of our social lives, and therefore are considered as a
key element of artificial agents that are expected to behave comparably
to humans \citep{boella2006normative}. We adopt Singh's
\shortcite{Singh-2013-Norms} representation of social norms in which norms
are classified as five types: commitment, authorization, prohibition,
sanction and power.


\section{Motivational Example}
\begin{example}
\label{ex:intro-ringer-meeting} 
Consider a ringer manager as a SIPA. The ringer manager installed on 
Alice's phone decides appropriate ringer modes (loud, silent, or 
vibrate) for incoming calls. Alice, the phone owner is the 
primary stakeholder of the SIPA. Bob, Alice's friend who 
calls Alice often, and Charlie and Dave, Alice's coworkers, who are in 
her vicinity, are some of the secondary stakeholders. Further, the ringer 
manager's capabilities influencing its social experience include
\begin{enumerate*}[label=(\arabic*)]
\item allowing Alice to be tele-reachable, 
\item notifying the caller if Alice is not reachable,
\item enabling Alice to work uninterrupted, and
\item not annoying Alice's neighbors.
\end{enumerate*}
\end{example}

Suppose that Bob calls Alice when she is in an important meeting with
Charlie and Dave. Alice is \emph{committed} (a social norm)
to answering Bob's phone calls. Another \emph{commitment} is to keep
one's phone silent during important meetings. Alice's SIPA,
understanding the norms and knowing that Bob's calls to Alice are
generally casual, puts Alice's phone on silent for Bob's call and
notifies Bob that Alice is in a meeting; later when Alice's meeting
ends, Alice's SIPA reminds her to call Bob.

Should Alice's phone rings loudly during the meeting, privacy
implications may follow
\citep{Murukannaiah-IC16-Engineering,solove-2006-taxonomy}. A loud ring
\emph{intrudes} upon Alice's and other meeting attendees' privacy in
that call violates the meeting attendees' reasonable expectation to be
left alone. Further, it is likely that meeting attendees frown at Alice
(\emph{disapprobation}). If Alice answers the call, those overhearing
Alice and Bob's conversation can gain knowledge about her and her
interlocutor (\emph{information leak}). If Bob's call were urgent, Bob's
SIPA could communicate the urgency to Alice's SIPA, and Alice's SIPA
could deliver a different social experience, e.g., set phone on vibrate
to notify Alice of urgency and yet not annoy other meeting attendees.
Should Alice's phone stays silent for Bob's urgent call, it may affect
their relationships.

In the examples above, ringer manager SIPA makes nontrivial decisions
influencing social experience of its stakeholders. Existing AOSE methods
\citep{Bresciani-JAAMAS04-Tropos,Winikoff-2004-DIA,Murukannaiah-AAMAS14-Xipho}
are good starting point to engineer personal agents, however these
methods do not guide developers with systematic steps to represent and
reason about such scenarios, and thus fall short in supporting agents
that adapt to evolving social contexts at runtime.

Social norms inform personal agents about a set of reasonable actions in a social
context \citep{vanRiemsdijk-AAMAS15-SociallyAdaptive}. Norm compliance in
a social context is either achieved by (1) conveyance of norms, where
SIPAs are made aware of norms by direct communication, or (2) via
(positive and negative) sanctions, where personal agents learn norms in the form
of which actions are appropriate in a context
\citep{Andrighetto-2013-PunishVoice}. 

Under certain circumstances, we (as humans) may deviate from norms. When
we deviate, we may offer an explanation typically revealing the context
of the deviation. Revealing context may lessen the burden of deviation,
and may help us avert sanction resulting from the deviation. Deviations
from norms often hint toward a different norm that is contextually
relevant. For instance if Alice reveals to meeting attendees' that the
call was from a sick friend who needs urgent care, the meeting
attendees' (1) may not frown on Alice, and (2) may learn that although
it is not appropriate to answer calls during meetings as it intrudes
upon attendees' privacy, answering an emergency call is acceptable as it
could ensure someone's well being or safety. An ability to reason about
deviation context, and an understanding of values promoted or demoted by different
actions could assist SIPAs in providing a pleasing social experience to
its stakeholders.

We recognize three key challenges. One, understanding what constitutes a
social experience, and how SIPA's actions influence the social
experience and privacy of its stakeholders? When SIPAs satisfy or violate
norms, they might share certain contextual information related to
satisfaction or violation. Social experience largely depends on how
SIPAs' stakeholders perceive shared information. Two, how and what
contextual information should a SIPA disclose? When norms conflict,
SIPAs must perform actions that promote richer social experience. Three,
how can we develop decision support to recommend actions?

\section{Research Questions}
\label{sec:intro-questions}

Based on aforementioned challenges and nuances in the example, we seek 
to probe the following research questions: 

\begin{description}

\item[RQ 1.] How can we model social intelligence in a SIPA such that it
delivers a social experience but respects its stakeholders' privacy?

\item[RQ 2.] How can we enable a SIPA to share deviation contexts, and to
reason about contexts shared by other SIPAs? 

\item[RQ 3.] Does a SIPA's ability to reason about \fsl{values} its actions could promote or demote, helps it in enriching the social
experience delivered to its stakeholders?

\end{description}

\section{Contributions and Organization}
\label{sec:intro-contributions}

To address the research questions of modeling social intelligence and
enabling ability to reason about deviation contexts and values, we
develop (1) \frameworkA, an AOSE method; (2) \frameworkB, a context
reasoning approach; and (3) \frameworkAinur, a value-based decision-making framework.

\subsection[Modeling Soical Intelligence via Norms]{\frameworkA: Modeling Social Intelligence via Norms in Privacy-Aware Personal Agents}

To address the research question of modeling social intelligence, we
develop \frameworkA \citep{Ajmeri-AAMAS17-Arnor}, a systematic 
AOSE method. It facilitates developers to model stakeholders' actions
and expectations, and how these influence each other. \frameworkA
employs Singh's \shortcite{Singh-2013-Norms} model of (social) norms to
capture social requirements, and incorporates argumentation constructs
\citep{BenchCapon-2007-Argumentation+AI} for sharing decision rationale.
Since, testing a SIPA's adaptability in all possible social contexts is
logistically challenging and time consuming, \frameworkA also
incorporates a SIPA simulation testbed. We rigorously evaluate
\frameworkA via a developer study and a set of simulation experiments on
the simulation testbed. 

%The novelty of the research is 
%that in spirit, \frameworkA is a hybrid method that addresses the 
%problem of engineering SIPA's by combining both top-down (by modeling) 
%and bottom-up (via experience or social learning) styles.

% \paragraph*{Developer Study} 
We hypothesize that the developers who follow \frameworkA (1) produce
better models, (2) expend less time, (3) feel it is easier to develop a
SIPA, and (4) expend less effort, than those who follow Xipho. We find
that developers using \frameworkA spend less time and effort, and
overall feel it is easier to engineer a SIPA using \frameworkA. No
significant difference is found in the model quality.

% \paragraph*{Simulation Experiment}
We hypothesize that SIPAs developed using \frameworkA (1) have better
adaptability features, and (2) provide richer social experience, than
SIPAs developed using Xipho. We measure social experience via norm
compliance and sanction proportion measures. We find that SIPAs
engineered using \frameworkA have greater adaptability correctness,
similar norm compliance, and are prone to lesser sanctions.

Chapter~\ref{chap:arnor} details \frameworkA, and discusses its evaluation. 

\subsection[Enhancing Social Experience via Context Sharing]{\frameworkB: Enhancing Social Experience via Context Sharing}

% As SIPAs act and interact, they need to be aware of their stakeholders'
% contexts, and how each stakeholder perceive their actions. To address
% the research question of sharing and reasoning about deviation contexts,
% we develop \frameworkB. \frameworkB is a framework which enables SIPAs
% to share deviation contexts with other agents, and provides SIPAs an
% ability to reason about contexts shared by other agents. This ability to
% share and reason about shared contexts assist SIPAs in inferring
% contextually relevant norms, and thus help SIPAs act in a way that
% provides a pleasing social experience to their stakeholders. We
% evaluated \frameworkB by social simulation experiments.

% \paragraph*{Simulation Experiment}
% We hypothesize that \frameworkB SIPAs that share and reason about
% context learn contextually relevant norms, and thus provide a greater
% social experience than those that don't reason about context. We measure
% social experience through happiness and experience payoff metrics
% (defined in Chapter~\ref{chap:poros}), and find that \frameworkB
% SIPAs provide higher happiness, and experience payoff.

Norms describe the social architecture of a society
and govern the interactions of its member agents.
It may be appropriate for an agent to deviate from
a norm; the deviation being indicative of a specialized
norm applying under a specific context. Existing
approaches for norm emergence assume simplified
interactions wherein deviations are negatively
sanctioned. We develop \frameworkB, an approach for
building SIPAs that carry out enriched interactions
where deviating SIPAs share selected elements of there 
context, and others respond appropriately.

% \paragraph*{Simulation Experiment}
We investigate via simulation the benefits
of such enriched interactions. We find
that as a result (1) the norms are learned better with
fewer sanctions, indicating improved social cohesion;
and (2) the agents are better able to satisfy
their individual goals. These results are robust under
societies of varying sizes and characteristics reflecting
pragmatic, considerate, and selfish agents.

Chapter~\ref{chap:poros} describes \frameworkB and its 
evaluation via simulation experiments. 

\subsection[Incorporating Values and Ethics]{\frameworkAinur: Incorporating Values and Ethics}
Privacy, values, and ethics are closely intertwined. 
Preserving privacy presumes understanding of human values 
and acting ethically. 
% 
If norms require agents to perform or not perform certain actions,
values provide a reason to or not to pursue those actions
\citep{Dechesne-AIL13-Norms+Values}. Each action a \frameworkB SIPA
executes, promotes or demotes certain \fsl{values}
\citep{pasotti-2016-normas}. For instance, a callee's action of
answering an urgent phone call during a meeting may promote \fsl{safety}
of the caller, but demote \fsl{privacy} of the meeting attendees'. 
Being aware of these values and an ability to reason about them 
helps a SIPA select ethical actions and yield pleasant experience.

We propose \frameworkAinur, a framework to design such ethical SIPAs. We incorporate a multicriteria decision-making method in \frameworkAinur
to aggregate value preferences of users and select an ethically 
appropriate action. 

% \paragraph*{Simulation Experiment}
 
We empirically evaluate \frameworkAinur via multiple simulation 
experiments. We find that agents developed using \frameworkAinur produce ethical actions that exhibit the
Rawlsian property of fairness and yield a pleasant social experience to its users.

Chapter~\ref{chap:ainur} describes \frameworkAinur, and its empirical evaluation. 